{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:03:27.853560Z",
     "start_time": "2020-03-26T14:03:23.925253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosneft_user_2500/anomaly-detection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      \n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      \n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:03:27.860268Z",
     "start_time": "2020-03-26T14:03:27.855703Z"
    }
   },
   "outputs": [],
   "source": [
    "root_folder = %pwd\n",
    "import sys\n",
    "sys.path = [root_folder] + sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:03:28.375881Z",
     "start_time": "2020-03-26T14:03:27.862674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of dataset: 12801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.features.build_features import rolling_window\n",
    "\n",
    "prediction_len = 1\n",
    "window_len = 32\n",
    "batch_size = 32\n",
    "\n",
    "data = pd.read_csv('data/processed/tep_data.csv', index_col='Index')\n",
    "print(f'Len of dataset: {data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:03:29.310393Z",
     "start_time": "2020-03-26T14:03:28.378771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9cc68fcb444299a74578dce39a90ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "@interact(component=(0, 40))\n",
    "def myacf(component):\n",
    "    plot_acf(data.values[:, component], lags=np.arange(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T17:40:26.565664Z",
     "start_time": "2020-03-26T17:40:25.544966Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79bdbce5fa84f47a2fbab0a9ba9f6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='comp', max=40), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.tsa.seasonal as seasonal\n",
    "period = 750\n",
    "decomposed = seasonal.seasonal_decompose(data.values,\n",
    "                                         period=period,\n",
    "                                         extrapolate_trend='freq')\n",
    "\n",
    "\n",
    "@interact(comp=(0, 40))\n",
    "def f(comp):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Trend')\n",
    "    plt.plot(decomposed.trend[:, comp])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Seasonal')\n",
    "    plt.plot(decomposed.seasonal[:, comp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:03:30.461452Z",
     "start_time": "2020-03-26T14:03:30.457973Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def get_log_path(name):\n",
    "    return name + '_' + datetime.now().strftime('%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:20:39.439770Z",
     "start_time": "2020-03-26T15:20:36.488266Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.torch.utils import to_dataloader\n",
    "\n",
    "X_trend = rolling_window(decomposed.trend, window_len)[:-prediction_len]\n",
    "y_trend = rolling_window(decomposed.trend, prediction_len, window_len)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_trend, y_trend, train_size=0.7, shuffle=False)\n",
    "\n",
    "train_set = to_dataloader(X_tr, y_tr, dict(batch_size=batch_size))\n",
    "test_set = to_dataloader(X_te, y_te, dict(batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T16:31:13.977445Z",
     "start_time": "2020-03-19T16:31:13.642640Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.torch.models import LSTM, Trainer\n",
    "\n",
    "config = dict(\n",
    "    input_size=X_tr[0].shape[1],\n",
    "    hidden_size=16,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=True,\n",
    ")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = LSTM(**config).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim,\n",
    "                                                       patience=3,\n",
    "                                                       threshold=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    device,\n",
    "    get_log_path(\n",
    "        f'logs/trend-{config[\"num_layers\"]}-layers-{config[\"hidden_size\"]}-hidden-{window_len}-len'\n",
    "    ),\n",
    "    stateful=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T14:10:49.866660Z",
     "start_time": "2020-03-12T14:10:49.862696Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # for test purpouses\n",
    "# sz = 200\n",
    "# xx = torch.rand(sz, window_len, data.shape[1])\n",
    "# yy = torch.rand(sz, data.shape[1])\n",
    "# xxdatayy = to_dataloader(xx, yy, dict(batch_size=batch_size))\n",
    "# trainer.train(xxdatayy, xxdatayy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T16:38:38.977713Z",
     "start_time": "2020-03-19T16:33:04.880949Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: :   0%|          | 0/280 [00:00<?, ?it/s, loss=0.66]/home/rosneft_user_2500/anomaly-detection/src/models/torch/utils.py:25: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "Epoch 0 of train: :   1%|          | 2/280 [00:00<00:22, 12.52it/s, loss=0.488]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.90it/s, loss=0.0189]\n",
      "Epoch 0 of val: : 100%|██████████| 120/120 [00:06<00:00, 17.15it/s, loss=0.317] \n",
      "Epoch 1 of train: :   1%|          | 2/280 [00:00<00:17, 15.90it/s, loss=0.185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0601\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.90it/s, loss=0.0142]\n",
      "Epoch 1 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.99it/s, loss=0.302] \n",
      "Epoch 2 of train: :   1%|          | 2/280 [00:00<00:14, 19.27it/s, loss=0.0812]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0480\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.27it/s, loss=0.0146] \n",
      "Epoch 2 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.34it/s, loss=0.187] \n",
      "Epoch 3 of train: :   1%|          | 2/280 [00:00<00:16, 17.01it/s, loss=0.0276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0357\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.50it/s, loss=0.0125] \n",
      "Epoch 3 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.89it/s, loss=0.185] \n",
      "Epoch 4 of train: :   1%|          | 2/280 [00:00<00:14, 19.19it/s, loss=0.0203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0303\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.41it/s, loss=0.0121] \n",
      "Epoch 4 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.52it/s, loss=0.228] \n",
      "Epoch 5 of train: :   1%|          | 2/280 [00:00<00:16, 16.73it/s, loss=0.0224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0328\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.50it/s, loss=0.0114] \n",
      "Epoch 5 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.51it/s, loss=0.219] \n",
      "Epoch 6 of train: :   1%|          | 2/280 [00:00<00:18, 15.41it/s, loss=0.0382]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0313\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.36it/s, loss=0.0102] \n",
      "Epoch 6 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.35it/s, loss=0.193] \n",
      "Epoch 7 of train: :   1%|          | 2/280 [00:00<00:16, 16.52it/s, loss=0.0169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0278\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.58it/s, loss=0.0105] \n",
      "Epoch 7 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.39it/s, loss=0.197] \n",
      "Epoch 8 of train: :   1%|          | 2/280 [00:00<00:14, 18.84it/s, loss=0.0187]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0291\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.50it/s, loss=0.0101] \n",
      "Epoch 8 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.39it/s, loss=0.185] \n",
      "Epoch 9 of train: :   1%|          | 2/280 [00:00<00:14, 19.49it/s, loss=0.016] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0269\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.66it/s, loss=0.00946]\n",
      "Epoch 9 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.02it/s, loss=0.186] \n",
      "Epoch 10 of train: :   1%|          | 2/280 [00:00<00:17, 15.88it/s, loss=0.0351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0280\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.45it/s, loss=0.0105] \n",
      "Epoch 10 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.96it/s, loss=0.196] \n",
      "Epoch 11 of train: :   1%|          | 2/280 [00:00<00:15, 18.47it/s, loss=0.0172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0293\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.84it/s, loss=0.00875]\n",
      "Epoch 11 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.02it/s, loss=0.177] \n",
      "Epoch 12 of train: :   1%|          | 2/280 [00:00<00:14, 19.81it/s, loss=0.0145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0286\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 of train: : 100%|██████████| 280/280 [00:14<00:00, 19.16it/s, loss=0.0101] \n",
      "Epoch 12 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.36it/s, loss=0.249] \n",
      "Epoch 13 of train: :   1%|          | 2/280 [00:00<00:15, 18.37it/s, loss=0.0493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0356\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.95it/s, loss=0.00902]\n",
      "Epoch 13 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.87it/s, loss=0.161] \n",
      "Epoch 14 of train: :   1%|          | 3/280 [00:00<00:13, 21.14it/s, loss=0.0202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0254\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.69it/s, loss=0.00919]\n",
      "Epoch 14 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.92it/s, loss=0.149] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_set, test_set, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T16:40:32.290447Z",
     "start_time": "2020-03-19T16:40:32.272706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'trend.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:20:22.464767Z",
     "start_time": "2020-03-26T15:20:22.385651Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load('trend.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:20:23.860831Z",
     "start_time": "2020-03-26T15:20:23.838003Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.torch.utils import to_dataloader, get_prev_states\n",
    "\n",
    "def next_value_foreceast(model, data, window_len):\n",
    "    model.eval()\n",
    "    pred = torch.zeros((0, data.shape[1]))\n",
    "    for i in tqdm(range(window_len, data.shape[0])):\n",
    "        inp = torch.tensor(data[i - window_len:i]).float()\n",
    "        inp = inp.view(1, *inp.size())\n",
    "        states = get_prev_states(model, 1)\n",
    "        pred = torch.cat((pred, model(inp, states)), dim=0)\n",
    "    return pred\n",
    "\n",
    "def forecast(model, prior, window_len, n):\n",
    "    model.eval()\n",
    "    inp = prior.view(1, window_len, -1)\n",
    "    for i in tqdm(range(n)):\n",
    "        states = get_prev_states(model, 1)\n",
    "        out = model(inp[:, -window_len:], states)\n",
    "        inp = torch.cat((inp, out.view(1, 1, -1)), dim=1)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:23:01.484665Z",
     "start_time": "2020-03-26T15:20:43.614294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8938 [00:00<?, ?it/s]/home/rosneft_user_2500/anomaly-detection/src/models/torch/utils.py:25: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "100%|██████████| 8938/8938 [01:27<00:00, 102.64it/s]\n",
      "100%|██████████| 3831/3831 [00:34<00:00, 110.38it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "split_point = len(X_tr) + window_len\n",
    "train_pred = next_value_foreceast(model, decomposed.trend[:split_point],\n",
    "                                   window_len)\n",
    "test_pred = next_value_foreceast(model, decomposed.trend[split_point-window_len:],\n",
    "                                  window_len)\n",
    "\n",
    "train_pred = train_pred.detach().numpy()\n",
    "test_pred = test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted MSE - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T13:32:19.685055Z",
     "start_time": "2020-03-12T13:32:19.680078Z"
    }
   },
   "source": [
    "На некоторых компонентах плохое предсказание, поэтому им нужно получить больше веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T14:16:53.367878Z",
     "start_time": "2020-03-12T14:16:53.294876Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# width = 3000\n",
    "# err = mean_squared_error(test_pred[:width], decomposed.trend[split_point:split_point+width], multioutput='raw_values')\n",
    "# plt.bar(np.arange(len(err)), err)\n",
    "\n",
    "# def weighted_mse_loss(weights):\n",
    "#     weights = torch.tensor(weights)\n",
    "#     criterion = torch.nn.MSELoss(reduction='none')\n",
    "#     def mse(input, target):\n",
    "#         nonlocal weights, criterion\n",
    "#         loss = criterion(input, target)\n",
    "#         loss = loss * weights.expand_as(loss)\n",
    "#         return loss.mean()\n",
    "#     return mse\n",
    "\n",
    "# criterion = weighted_mse_loss(err / err.sum())\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim,\n",
    "#                                                        patience=3,\n",
    "#                                                        threshold=0.01)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     criterion,\n",
    "#     optim,\n",
    "#     scheduler,\n",
    "#     device,\n",
    "#     get_log_path(\n",
    "#         f'logs/trend-retraining-{config[\"num_layers\"]}-layers-{config[\"hidden_size\"]}-hidden-{window_len}-len'\n",
    "#     ),\n",
    "#     stateful=True)\n",
    "\n",
    "\n",
    "\n",
    "# model.reset_states()\n",
    "# trainer.train(train_set, test_set, 10)\n",
    "\n",
    "# model.reset_states()\n",
    "# split_point = len(X_tr) + window_len\n",
    "# train_pred = next_value_prediction(model, decomposed.trend[:split_point],\n",
    "#                                    window_len)\n",
    "# test_pred = next_value_prediction(model, decomposed.trend[split_point:],\n",
    "#                                   window_len)\n",
    "\n",
    "# train_pred = train_pred.detach().numpy()\n",
    "# test_pred = test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T14:26:48.410299Z",
     "start_time": "2020-03-12T14:26:47.341223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c1d00f230740a4adcb7db7f7bb6900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(component=(0, 40))\n",
    "def plot(component):\n",
    "    width = 3000\n",
    "    global split_point\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.suptitle('Next value prediction of trend')\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Train')\n",
    "    plt.plot(decomposed.trend[:width + window_len, component],\n",
    "             label='real',\n",
    "             alpha=0.7)\n",
    "    plt.plot(list(range(window_len, window_len + width)),\n",
    "             train_pred[:width, component],\n",
    "             label='pred',\n",
    "             alpha=0.8)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Test')\n",
    "    plt.plot(decomposed.trend[split_point:split_point + width, component],\n",
    "             label='real',\n",
    "             alpha=0.7)\n",
    "    plt.plot(list(range(window_len, window_len + width)),\n",
    "             test_pred[:width, component],\n",
    "             label='pred',\n",
    "             alpha=0.8)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T14:13:48.426421Z",
     "start_time": "2020-03-12T14:10:40.443Z"
    }
   },
   "outputs": [],
   "source": [
    "# inp = torch.cat(\n",
    "#     (torch.tensor(decomposed.trend[len(X_tr) + 1 - window_len:len(X_tr)]).float(), torch.tensor(train_pred[-1, None, :])),\n",
    "#     axis=0).view(1, window_len, data.shape[1])\n",
    "# for i in tqdm(range(len(X_te))):\n",
    "#     states = get_prev_states(model, 1)\n",
    "#     out = model(inp[:, -window_len:], states)\n",
    "#     inp = torch.cat((inp, out.view(1, 1, -1)), axis=1)\n",
    "    \n",
    "# pred = inp.squeeze().detach().numpy()[window_len:]\n",
    "\n",
    "# @interact(component=(0, 40))\n",
    "# def f(component):\n",
    "#     sz = 100\n",
    "#     plt.title(f'Next {sz} values prediction of trend')\n",
    "#     plt.plot(pred[:sz, component], label='pred')\n",
    "#     plt.plot(decomposed.trend[len(X_tr):len(X_tr)+sz, component], label='ground truth')\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сезонная "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Преобразование фурье"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:09.617257Z",
     "start_time": "2020-03-26T14:31:09.611683Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_seasonal = decomposed.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:11.126261Z",
     "start_time": "2020-03-26T14:31:10.011150Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 12770, 34)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import stft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "f, t, Zxx = stft(X_seasonal, axis=0, nperseg=window_len, noverlap=window_len-1, \n",
    "                 return_onesided=True, boundary=None, padded=False)\n",
    "\n",
    "Zxx = np.swapaxes(Zxx, 0, 1)\n",
    "Zxx = np.swapaxes(Zxx, 1, 2)\n",
    "Zxx = np.concatenate((Zxx.real, Zxx.imag), axis=-1)\n",
    "\n",
    "print(Zxx.shape)\n",
    "\n",
    "ss = StandardScaler()\n",
    "for i in range(Zxx.shape[0]):\n",
    "    Zxx[i] = ss.fit_transform(Zxx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:11.256401Z",
     "start_time": "2020-03-26T14:31:11.128319Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12770, 41, 34)\n"
     ]
    }
   ],
   "source": [
    "Zxx = np.swapaxes(Zxx, 0, 1)\n",
    "print(Zxx.shape)\n",
    "\n",
    "Zxx = Zxx.reshape(Zxx.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:18.320214Z",
     "start_time": "2020-03-26T14:31:18.315681Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(svd_solver='full', whiten=True)\n",
    "# pca.fit(Zxx)\n",
    "\n",
    "# min_idx = np.argmax(np.where(np.isclose(np.cumsum(pca.explained_variance_ratio_), 1))[0])\n",
    "# min_idx\n",
    "\n",
    "# Zxx = pca.transform(Zxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:21.514924Z",
     "start_time": "2020-03-26T14:31:21.215154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_seasonal = Zxx[:-prediction_len]\n",
    "y_seasonal = Zxx[prediction_len:]\n",
    "\n",
    "X_seas_tr, X_seas_te, y_seas_tr, y_seas_te = train_test_split(X_seasonal, y_seasonal, train_size=0.7, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:24.196329Z",
     "start_time": "2020-03-26T14:31:24.069811Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from src.models.torch.models import LSTM, Trainer\n",
    "from src.models.torch.utils import to_dataloader, get_prev_states\n",
    "import torch\n",
    "\n",
    "seas_train_set = to_dataloader(X_seas_tr, y_seas_tr, dict(batch_size=batch_size, shuffle=True))\n",
    "seas_test_set = to_dataloader(X_seas_te, y_seas_te, dict(batch_size=batch_size, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:49.149383Z",
     "start_time": "2020-03-26T14:31:49.112090Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "latent_dim = 512\n",
    "\n",
    "seas_model = nn.Sequential(\n",
    "    nn.Linear(X_seasonal.shape[1], latent_dim),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(latent_dim, X_seasonal.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:51.280997Z",
     "start_time": "2020-03-26T14:31:50.511393Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 12769, 512]         714,240\n",
      "              Tanh-2           [-1, 12769, 512]               0\n",
      "            Linear-3          [-1, 12769, 1394]         715,122\n",
      "================================================================\n",
      "Total params: 1,429,362\n",
      "Trainable params: 1,429,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 67.90\n",
      "Forward/backward pass size (MB): 235.56\n",
      "Params size (MB): 5.45\n",
      "Estimated Total Size (MB): 308.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(seas_model, input_size=(X_seasonal.shape[0], X_seasonal.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:31:57.706386Z",
     "start_time": "2020-03-26T14:31:57.667259Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss\n",
    "\n",
    "optimizer = torch.optim.Adam(seas_model.parameters())\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "trainer = create_supervised_trainer(seas_model, optimizer, loss)\n",
    "evaluator = create_supervised_evaluator(seas_model, metrics={'loss': Loss(loss)})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_metrics(engine):\n",
    "    evaluator.run(seas_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:32:32.109577Z",
     "start_time": "2020-03-26T14:32:32.087504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers.tensorboard_logger import *\n",
    "\n",
    "# Create a logger\n",
    "tb_logger = TensorboardLogger(log_dir=get_log_path('logs/seas'))\n",
    "\n",
    "tb_logger.attach(trainer,\n",
    "                 log_handler=OutputHandler(\n",
    "                     tag=\"training\",\n",
    "                     output_transform=lambda loss: {'MSE': loss}),\n",
    "                 event_name=Events.ITERATION_COMPLETED)\n",
    "\n",
    "tb_logger.attach(evaluator,\n",
    "                 log_handler=OutputHandler(\n",
    "                     tag=\"validation\",\n",
    "                     metric_names=[\"loss\"],\n",
    "                     global_step_transform=global_step_from_engine(trainer)),\n",
    "                 event_name=Events.EPOCH_COMPLETED)\n",
    "\n",
    "tb_logger.attach(trainer,\n",
    "                 log_handler=OptimizerParamsHandler(optimizer),\n",
    "                 event_name=Events.ITERATION_STARTED)\n",
    "\n",
    "tb_logger.attach(trainer,\n",
    "                 log_handler=GradsHistHandler(seas_model),\n",
    "                 event_name=Events.EPOCH_COMPLETED)\n",
    "\n",
    "# We need to close the logger with we are done\n",
    "tb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:34:00.833775Z",
     "start_time": "2020-03-26T14:32:36.067562Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainer.run(seas_train_set, max_epochs=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:34:00.843373Z",
     "start_time": "2020-03-26T14:34:00.836753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def next_value_foreceast(model, data):\n",
    "    model.eval()\n",
    "    pred = torch.zeros((0, *data.shape[1:]))\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        inp = torch.tensor(data[i]).float()\n",
    "        inp = inp.view(1, *inp.size())\n",
    "        pred = torch.cat((pred, model(inp)), dim=0)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:38:04.268365Z",
     "start_time": "2020-03-26T14:34:52.918866Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8938/8938 [02:57<00:00, 50.28it/s] \n",
      "100%|██████████| 3831/3831 [00:13<00:00, 284.55it/s]\n"
     ]
    }
   ],
   "source": [
    "seas_forecast_tr = next_value_foreceast(seas_model, X_seas_tr).detach().numpy()\n",
    "seas_forecast_te = next_value_foreceast(seas_model, X_seas_te).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:16:33.055929Z",
     "start_time": "2020-03-26T14:16:32.425485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seas_forecast_tr = pca.inverse_transform(seas_forecast_tr)\n",
    "# seas_forecast_te = pca.inverse_transform(seas_forecast_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:47:51.839951Z",
     "start_time": "2020-03-26T14:47:51.831907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seas_forecast_tr = seas_forecast_tr.reshape(-1, 41, 34)\n",
    "seas_forecast_te = seas_forecast_te.reshape(-1, 41, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T14:48:59.393812Z",
     "start_time": "2020-03-26T14:48:58.898418Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1da3e01d15044ccac7ad9a763224350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1915, description='idx', max=3831), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "@interact(idx=(0, len(X_seas_te)))\n",
    "def plot_diff_stft(idx):\n",
    "    plt.figure(figsize=(6, 10))\n",
    "    plt.title('Difference between true spectr and predicted')\n",
    "#     diff = seas_forecast_te[idx] - pca.inverse_transform(X_seasonal[len(X_seas_tr) + idx]).reshape(41, 34)\n",
    "    diff = seas_forecast_te[idx] - X_seasonal[len(X_seas_tr) + idx].reshape(41, 34)\n",
    "    diff = np.abs(diff)\n",
    "    plt.imshow(diff)\n",
    "    print(diff.sum())\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:08:13.050564Z",
     "start_time": "2020-03-26T15:08:12.088717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import istft\n",
    "def to_spectr(seas_forecast):\n",
    "    spectr = np.split(seas_forecast, 2, axis=-1)\n",
    "    spectr = spectr[0] + 1j * spectr[1]\n",
    "    return istft(spectr, time_axis=0, freq_axis=2, nperseg=window_len, noverlap=window_len-1)[1]\n",
    "\n",
    "seas_tr = to_spectr(seas_forecast_tr)\n",
    "seas_te = to_spectr(seas_forecast_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T15:15:59.251165Z",
     "start_time": "2020-03-26T15:15:58.390683Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd084f3575b4e85946921ebba133747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "split_point = len(X_seasonal) + window_len\n",
    "\n",
    "@interact(component=(0, 40))\n",
    "def plot(component):\n",
    "    width = 3000\n",
    "    global split_point\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.suptitle('Next value prediction of Seasonal')\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Train')\n",
    "    plt.plot(decomposed.seasonal[:width + window_len, component],\n",
    "             label='real',\n",
    "             alpha=0.7)\n",
    "    plt.plot(list(range(window_len, window_len + width)),\n",
    "             seas_tr[:width, component],\n",
    "             label='pred',\n",
    "             alpha=0.8)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Test')\n",
    "    plt.plot(decomposed.seasonal[split_point:split_point + width, component],\n",
    "             label='real',\n",
    "             alpha=0.7)\n",
    "    plt.plot(list(range(window_len, window_len + width)),\n",
    "             seas_te[:width, component],\n",
    "             label='pred',\n",
    "             alpha=0.8)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T17:05:54.256889Z",
     "start_time": "2020-03-26T17:05:54.240166Z"
    }
   },
   "outputs": [],
   "source": [
    "train_resid = np.array(y_tr).squeeze() - train_pred\n",
    "test_resid = np.array(y_te).squeeze() - test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T20:11:06.996735Z",
     "start_time": "2020-03-26T20:11:06.267919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a4b6f21ed04bc8bdc0fff6b2aa2aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(component=(0, 40))\n",
    "def plot_trend_resid(component):\n",
    "    plt.figure(figsize=(20, 12))\n",
    "\n",
    "    trend_pred = np.r_[train_pred, test_pred]\n",
    "    residuals = np.r_[train_resid, test_resid]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Trend')\n",
    "    plt.plot(trend_pred[:, component], label='Next value prediction (LSTM)')\n",
    "    plt.plot(decomposed.trend[:, component], label='Real')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(residuals[:, component], label='Residuals (data - trend_pred)')\n",
    "#     plt.plot(decomposed.seasonal[:, component] + decomposed.resid[:, component], \n",
    "#              label='Seasonal + Resid', \n",
    "#              alpha=0.6)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:20:43.235247Z",
     "start_time": "2020-03-20T08:20:43.206497Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler().fit(train_resid)\n",
    "train_resid_scaled = ss.transform(train_resid)\n",
    "test_resid_scaled = ss.transform(test_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:23:37.114777Z",
     "start_time": "2020-03-20T08:23:34.046270Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = to_dataloader(X_tr, train_resid_scaled, dict(batch_size=batch_size))\n",
    "test_set = to_dataloader(X_te, test_resid_scaled, dict(batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:34:25.334294Z",
     "start_time": "2020-03-20T08:34:25.310602Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.torch.models import LSTM, Trainer\n",
    "\n",
    "config = dict(\n",
    "    input_size=X_tr[0].shape[1],\n",
    "    hidden_size=16,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=True,\n",
    ")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = LSTM(**config).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim,\n",
    "                                                       patience=3,\n",
    "                                                       threshold=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    device,\n",
    "    get_log_path(\n",
    "        f'logs/resid-{config[\"num_layers\"]}-layers-{config[\"hidden_size\"]}-hidden-{window_len}-len'\n",
    "    ),\n",
    "    stateful=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:38:13.291133Z",
     "start_time": "2020-03-20T08:34:28.225637Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: :   1%|          | 2/280 [00:00<00:19, 14.35it/s, loss=3.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.00it/s, loss=1.1]  \n",
      "Epoch 0 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.25it/s, loss=25.7]\n",
      "Epoch 1 of train: :   1%|          | 2/280 [00:00<00:14, 19.41it/s, loss=2.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.3518\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of train: : 100%|██████████| 280/280 [00:16<00:00, 17.37it/s, loss=1.02] \n",
      "Epoch 1 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.27it/s, loss=26.5]\n",
      "Epoch 2 of train: :   1%|          | 2/280 [00:00<00:18, 15.17it/s, loss=2.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.4708\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.96it/s, loss=1.05] \n",
      "Epoch 2 of val: : 100%|██████████| 120/120 [00:06<00:00, 17.27it/s, loss=25.5]\n",
      "Epoch 3 of train: :   1%|          | 2/280 [00:00<00:14, 19.13it/s, loss=1.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.4141\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 of train: : 100%|██████████| 280/280 [00:15<00:00, 17.66it/s, loss=1.07] \n",
      "Epoch 3 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.02it/s, loss=23.7]\n",
      "Epoch 4 of train: :   1%|          | 2/280 [00:00<00:17, 16.09it/s, loss=2.92]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.2035\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.31it/s, loss=1.04] \n",
      "Epoch 4 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.20it/s, loss=25]  \n",
      "Epoch 5 of train: :   1%|          | 2/280 [00:00<00:15, 18.15it/s, loss=1.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.3363\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.52it/s, loss=1.06] \n",
      "Epoch 5 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.50it/s, loss=24.9]\n",
      "Epoch 6 of train: :   1%|          | 3/280 [00:00<00:13, 21.13it/s, loss=1.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.2944\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.61it/s, loss=1.06] \n",
      "Epoch 6 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.46it/s, loss=25.1]\n",
      "Epoch 7 of train: :   1%|          | 2/280 [00:00<00:15, 17.60it/s, loss=1.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.3325\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.77it/s, loss=1.08] \n",
      "Epoch 7 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.62it/s, loss=26.5]\n",
      "Epoch 8 of train: :   1%|          | 2/280 [00:00<00:13, 19.88it/s, loss=2.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.3813\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.86it/s, loss=1.1]  \n",
      "Epoch 8 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.02it/s, loss=24.7]\n",
      "Epoch 9 of train: :   1%|          | 2/280 [00:00<00:15, 18.27it/s, loss=2.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.1734\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.57it/s, loss=1.1]  \n",
      "Epoch 9 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.97it/s, loss=24.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_set, test_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
