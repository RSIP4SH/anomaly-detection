{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:15.623666Z",
     "start_time": "2020-04-03T07:26:08.120215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosneft_user_2500/anomaly-detection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      \n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      \n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:15.635279Z",
     "start_time": "2020-04-03T07:26:15.627908Z"
    }
   },
   "outputs": [],
   "source": [
    "root_folder = %pwd\n",
    "import sys\n",
    "sys.path = [root_folder] + sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:16.642415Z",
     "start_time": "2020-04-03T07:26:15.639166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of dataset: 12801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.features.build_features import rolling_window\n",
    "\n",
    "prediction_len = 1\n",
    "window_len = 32\n",
    "batch_size = 32\n",
    "\n",
    "data = pd.read_csv('data/processed/tep_data.csv', index_col='Index')\n",
    "print(f'Len of dataset: {data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:18.048687Z",
     "start_time": "2020-04-03T07:26:16.645822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102fd573f82b49848ef66df00b556731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "@interact(component=(0, 40))\n",
    "def myacf(component):\n",
    "    plot_acf(data.values[:, component], lags=np.arange(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:19.203277Z",
     "start_time": "2020-04-03T07:26:18.051392Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e7fe075abc4f81840a7c8dd1d91718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='comp', max=40), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.tsa.seasonal as seasonal\n",
    "period = 750\n",
    "decomposed = seasonal.seasonal_decompose(data.values,\n",
    "                                         period=period,\n",
    "                                         extrapolate_trend='freq')\n",
    "\n",
    "\n",
    "@interact(comp=(0, 40))\n",
    "def f(comp):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Trend')\n",
    "    plt.plot(decomposed.trend[:, comp])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Seasonal')\n",
    "    plt.plot(decomposed.seasonal[:, comp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:29.179263Z",
     "start_time": "2020-04-03T07:26:29.172225Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def get_log_path(name):\n",
    "    return name + '_' + datetime.now().strftime('%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:26:29.589324Z",
     "start_time": "2020-04-03T07:26:29.563978Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_plot_1d(real, real_lbl, pred, pred_lbl, shift_pred=0):\n",
    "    plt.plot(real, label=real_lbl, alpha=0.7)\n",
    "    plt.plot(list(range(shift_pred, real.shape[0])), pred, label=pred_lbl, alpha=0.8)\n",
    "    plt.legend()\n",
    "\n",
    "def compare_plot_from_2d(real, real_lbl, pred, pred_lbl, component, shift_pred=0):\n",
    "    real_comp = real[:, component]\n",
    "    pred_comp = pred[:, component]\n",
    "    compare_plot_1d(real_comp,real_lbl, pred_comp, pred_lbl, shift_pred)\n",
    "    \n",
    "def compare_plot_from_2d_wrapper(*args, **kwargs):\n",
    "    def f(**inner_kwargs):\n",
    "        return compare_plot_from_2d(*args, **kwargs, **inner_kwargs)\n",
    "    return f\n",
    "\n",
    "def interactive_plotter_by_component(funcs, titles, suptitle):\n",
    "    @interact(component=(0, data.shape[1]-1))\n",
    "    def __inner__(component):\n",
    "        plt.figure(figsize=(18, 8))\n",
    "        plt.suptitle(suptitle)\n",
    "        for i, (func, title) in enumerate(zip(funcs, titles), 1):\n",
    "            plt.subplot(1, len(funcs), i)\n",
    "            plt.title(title)\n",
    "            func(component=component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Тренд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:27:02.666706Z",
     "start_time": "2020-04-03T07:26:57.834363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from src.models.torch.utils import to_dataloader\n",
    "\n",
    "X_trend = rolling_window(decomposed.trend, window_len)[:-prediction_len]\n",
    "y_trend = rolling_window(decomposed.trend, prediction_len, window_len)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_trend, y_trend, train_size=0.7, shuffle=False)\n",
    "\n",
    "train_set = to_dataloader(X_tr, y_tr, dict(batch_size=batch_size))\n",
    "test_set = to_dataloader(X_te, y_te, dict(batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:43:28.276705Z",
     "start_time": "2020-04-01T08:43:26.175928Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.torch.models import LSTM, Trainer\n",
    "\n",
    "config = dict(\n",
    "    input_size=X_tr[0].shape[1],\n",
    "    hidden_size=16,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=True,\n",
    ")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = LSTM(**config).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim,\n",
    "                                                       patience=3,\n",
    "                                                       threshold=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    device,\n",
    "    get_log_path(\n",
    "        f'logs/trend-{config[\"num_layers\"]}-layers-{config[\"hidden_size\"]}-hidden-{window_len}-len'\n",
    "    ),\n",
    "    stateful=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T14:10:49.866660Z",
     "start_time": "2020-03-12T14:10:49.862696Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # for test purpouses\n",
    "# sz = 200\n",
    "# xx = torch.rand(sz, window_len, data.shape[1])\n",
    "# yy = torch.rand(sz, data.shape[1])\n",
    "# xxdatayy = to_dataloader(xx, yy, dict(batch_size=batch_size))\n",
    "# trainer.train(xxdatayy, xxdatayy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T16:38:38.977713Z",
     "start_time": "2020-03-19T16:33:04.880949Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: :   0%|          | 0/280 [00:00<?, ?it/s, loss=0.66]/home/rosneft_user_2500/anomaly-detection/src/models/torch/utils.py:25: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "Epoch 0 of train: :   1%|          | 2/280 [00:00<00:22, 12.52it/s, loss=0.488]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.90it/s, loss=0.0189]\n",
      "Epoch 0 of val: : 100%|██████████| 120/120 [00:06<00:00, 17.15it/s, loss=0.317] \n",
      "Epoch 1 of train: :   1%|          | 2/280 [00:00<00:17, 15.90it/s, loss=0.185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0601\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.90it/s, loss=0.0142]\n",
      "Epoch 1 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.99it/s, loss=0.302] \n",
      "Epoch 2 of train: :   1%|          | 2/280 [00:00<00:14, 19.27it/s, loss=0.0812]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0480\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.27it/s, loss=0.0146] \n",
      "Epoch 2 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.34it/s, loss=0.187] \n",
      "Epoch 3 of train: :   1%|          | 2/280 [00:00<00:16, 17.01it/s, loss=0.0276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0357\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.50it/s, loss=0.0125] \n",
      "Epoch 3 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.89it/s, loss=0.185] \n",
      "Epoch 4 of train: :   1%|          | 2/280 [00:00<00:14, 19.19it/s, loss=0.0203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0303\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.41it/s, loss=0.0121] \n",
      "Epoch 4 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.52it/s, loss=0.228] \n",
      "Epoch 5 of train: :   1%|          | 2/280 [00:00<00:16, 16.73it/s, loss=0.0224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0328\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.50it/s, loss=0.0114] \n",
      "Epoch 5 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.51it/s, loss=0.219] \n",
      "Epoch 6 of train: :   1%|          | 2/280 [00:00<00:18, 15.41it/s, loss=0.0382]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0313\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.36it/s, loss=0.0102] \n",
      "Epoch 6 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.35it/s, loss=0.193] \n",
      "Epoch 7 of train: :   1%|          | 2/280 [00:00<00:16, 16.52it/s, loss=0.0169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0278\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.58it/s, loss=0.0105] \n",
      "Epoch 7 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.39it/s, loss=0.197] \n",
      "Epoch 8 of train: :   1%|          | 2/280 [00:00<00:14, 18.84it/s, loss=0.0187]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0291\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.50it/s, loss=0.0101] \n",
      "Epoch 8 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.39it/s, loss=0.185] \n",
      "Epoch 9 of train: :   1%|          | 2/280 [00:00<00:14, 19.49it/s, loss=0.016] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0269\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.66it/s, loss=0.00946]\n",
      "Epoch 9 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.02it/s, loss=0.186] \n",
      "Epoch 10 of train: :   1%|          | 2/280 [00:00<00:17, 15.88it/s, loss=0.0351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0280\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 of train: : 100%|██████████| 280/280 [00:15<00:00, 18.45it/s, loss=0.0105] \n",
      "Epoch 10 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.96it/s, loss=0.196] \n",
      "Epoch 11 of train: :   1%|          | 2/280 [00:00<00:15, 18.47it/s, loss=0.0172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0293\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.84it/s, loss=0.00875]\n",
      "Epoch 11 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.02it/s, loss=0.177] \n",
      "Epoch 12 of train: :   1%|          | 2/280 [00:00<00:14, 19.81it/s, loss=0.0145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0286\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 of train: : 100%|██████████| 280/280 [00:14<00:00, 19.16it/s, loss=0.0101] \n",
      "Epoch 12 of val: : 100%|██████████| 120/120 [00:06<00:00, 19.36it/s, loss=0.249] \n",
      "Epoch 13 of train: :   1%|          | 2/280 [00:00<00:15, 18.37it/s, loss=0.0493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0356\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.95it/s, loss=0.00902]\n",
      "Epoch 13 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.87it/s, loss=0.161] \n",
      "Epoch 14 of train: :   1%|          | 3/280 [00:00<00:13, 21.14it/s, loss=0.0202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0254\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 of train: : 100%|██████████| 280/280 [00:14<00:00, 18.69it/s, loss=0.00919]\n",
      "Epoch 14 of val: : 100%|██████████| 120/120 [00:06<00:00, 18.92it/s, loss=0.149] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_set, test_set, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T16:40:32.290447Z",
     "start_time": "2020-03-19T16:40:32.272706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'trend.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:27:09.993793Z",
     "start_time": "2020-04-03T07:27:09.054851Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosneft_user_2500/anaconda3/envs/anom-det/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning:\n",
      "\n",
      "source code of class 'src.models.torch.models.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load('trend.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:27:20.338857Z",
     "start_time": "2020-04-03T07:27:20.328862Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def forecast_tr_te(model, X_tr, X_te, batch_size):\n",
    "    model.reset_states()\n",
    "    if len(X_tr) % batch_size:\n",
    "        raise ValueError('Len of X_tr must be divisible by batch size')\n",
    "    train_pred = model.forecast(X_tr, batch_size)\n",
    "    test_pred = model.forecast(X_te, batch_size)\n",
    "    return train_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:27:29.690765Z",
     "start_time": "2020-04-03T07:27:21.706192Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/218 [00:00<00:55,  3.89it/s]/home/rosneft_user_2500/anomaly-detection/src/models/torch/models.py:45: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "100%|██████████| 218/218 [00:05<00:00, 40.04it/s]\n",
      "100%|██████████| 94/94 [00:02<00:00, 43.05it/s]\n"
     ]
    }
   ],
   "source": [
    "train_pred, test_pred = forecast_tr_te(model, X_tr, X_te, 41)\n",
    "\n",
    "train_pred = train_pred.detach().numpy()\n",
    "test_pred = test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:27:46.349475Z",
     "start_time": "2020-04-03T07:27:45.668732Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_point = len(X_tr) + window_len\n",
    "\n",
    "interactive_plotter_by_component([\n",
    "    compare_plot_from_2d_wrapper(decomposed.trend[:split_point],\n",
    "                                 'real',\n",
    "                                 train_pred,\n",
    "                                 'pred',\n",
    "                                 shift_pred=window_len),\n",
    "    compare_plot_from_2d_wrapper(decomposed.trend[split_point:], 'real',\n",
    "                                 test_pred, 'pred')\n",
    "], ['Train', 'Test'], 'Next value prediction of trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Weighted MSE - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T13:32:19.685055Z",
     "start_time": "2020-03-12T13:32:19.680078Z"
    },
    "hidden": true
   },
   "source": [
    "На некоторых компонентах плохое предсказание, поэтому им нужно получить больше веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T14:16:53.367878Z",
     "start_time": "2020-03-12T14:16:53.294876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# width = 3000\n",
    "# err = mean_squared_error(test_pred[:width], decomposed.trend[split_point:split_point+width], multioutput='raw_values')\n",
    "# plt.bar(np.arange(len(err)), err)\n",
    "\n",
    "# def weighted_mse_loss(weights):\n",
    "#     weights = torch.tensor(weights)\n",
    "#     criterion = torch.nn.MSELoss(reduction='none')\n",
    "#     def mse(input, target):\n",
    "#         nonlocal weights, criterion\n",
    "#         loss = criterion(input, target)\n",
    "#         loss = loss * weights.expand_as(loss)\n",
    "#         return loss.mean()\n",
    "#     return mse\n",
    "\n",
    "# criterion = weighted_mse_loss(err / err.sum())\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim,\n",
    "#                                                        patience=3,\n",
    "#                                                        threshold=0.01)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     criterion,\n",
    "#     optim,\n",
    "#     scheduler,\n",
    "#     device,\n",
    "#     get_log_path(\n",
    "#         f'logs/trend-retraining-{config[\"num_layers\"]}-layers-{config[\"hidden_size\"]}-hidden-{window_len}-len'\n",
    "#     ),\n",
    "#     stateful=True)\n",
    "\n",
    "\n",
    "\n",
    "# model.reset_states()\n",
    "# trainer.train(train_set, test_set, 10)\n",
    "\n",
    "# model.reset_states()\n",
    "# split_point = len(X_tr) + window_len\n",
    "# train_pred = next_value_prediction(model, decomposed.trend[:split_point],\n",
    "#                                    window_len)\n",
    "# test_pred = next_value_prediction(model, decomposed.trend[split_point:],\n",
    "#                                   window_len)\n",
    "\n",
    "# train_pred = train_pred.detach().numpy()\n",
    "# test_pred = test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание остатков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подоготвка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:32:22.169265Z",
     "start_time": "2020-04-03T07:32:22.132994Z"
    }
   },
   "outputs": [],
   "source": [
    "train_resid = np.array(y_tr).squeeze() - train_pred\n",
    "test_resid = np.array(y_te).squeeze() - test_pred\n",
    "\n",
    "trend_pred = np.r_[train_pred, test_pred]\n",
    "residuals = np.r_[train_resid, test_resid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:32:22.973848Z",
     "start_time": "2020-04-03T07:32:22.300229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1073f208524f4df091baaa30f6595c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plotter_by_component([\n",
    "    compare_plot_from_2d_wrapper(decomposed.trend,\n",
    "                                 'real',\n",
    "                                 trend_pred,\n",
    "                                 'Next value prediction (LSTM)',\n",
    "                                 shift_pred=window_len),\n",
    "    lambda component: plt.plot(residuals[:, component], label='Residuals (data - trend_pred)')\n",
    "],\n",
    "['Trend', 'Resid'], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:32:29.330692Z",
     "start_time": "2020-04-03T07:32:26.053987Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446996c1db6b4b51a47dd4bdd53a1a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Dropdown(description='sigma', opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "@interact(component=(0, 40), sigma=np.arange(1, 11))\n",
    "def plot(component, sigma):\n",
    "    smoothed = gaussian_filter1d(train_resid, sigma, axis=0)\n",
    "    pd.DataFrame(dict(component=smoothed[:, component])).iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:32:29.367926Z",
     "start_time": "2020-04-03T07:32:29.333067Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "smoothed_train = gaussian_filter1d(train_resid, sigma, axis=0)\n",
    "smoothed_test = gaussian_filter1d(test_resid, sigma, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T08:20:43.235247Z",
     "start_time": "2020-03-20T08:20:43.206497Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler().fit(train_resid)\n",
    "# train_resid_scaled = ss.transform(smoothed_train)\n",
    "# test_resid_scaled = ss.transform(smoothed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T10:10:29.469069Z",
     "start_time": "2020-04-01T10:10:26.404679Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = to_dataloader(X_tr, smoothed_train, dict(batch_size=batch_size))\n",
    "test_set = to_dataloader(X_te, smoothed_test, dict(batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T10:11:04.179128Z",
     "start_time": "2020-04-01T10:11:04.162860Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.torch.models import LSTM, Trainer\n",
    "\n",
    "config = dict(\n",
    "    input_size=X_tr[0].shape[1],\n",
    "    hidden_size=16,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=True,\n",
    ")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = LSTM(**config).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim,\n",
    "                                                       patience=3,\n",
    "                                                       threshold=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    optim,\n",
    "    scheduler,\n",
    "    device,\n",
    "    get_log_path(\n",
    "        f'logs/resid-smoothed-{config[\"num_layers\"]}-layers-{config[\"hidden_size\"]}-hidden-{window_len}-len'\n",
    "    ),\n",
    "    stateful=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T10:15:14.072688Z",
     "start_time": "2020-04-01T10:11:06.271178Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: :   0%|          | 0/280 [00:00<?, ?it/s, loss=0.104]/home/rosneft_user_2500/anomaly-detection/src/models/torch/utils.py:25: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "Epoch 0 of train: :   1%|          | 2/280 [00:00<00:25, 11.08it/s, loss=0.0621]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 of train: : 100%|██████████| 280/280 [00:17<00:00, 15.98it/s, loss=0.0085] \n",
      "Epoch 0 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.78it/s, loss=0.135] \n",
      "Epoch 1 of train: :   0%|          | 1/280 [00:00<00:28,  9.65it/s, loss=0.0389]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0240\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of train: : 100%|██████████| 280/280 [00:17<00:00, 16.36it/s, loss=0.00782]\n",
      "Epoch 1 of val: : 100%|██████████| 120/120 [00:07<00:00, 15.90it/s, loss=0.126] \n",
      "Epoch 2 of train: :   1%|          | 2/280 [00:00<00:24, 11.27it/s, loss=0.0314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0214\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.89it/s, loss=0.00668]\n",
      "Epoch 2 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.79it/s, loss=0.113] \n",
      "Epoch 3 of train: :   1%|          | 2/280 [00:00<00:22, 12.22it/s, loss=0.0118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0201\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 of train: : 100%|██████████| 280/280 [00:17<00:00, 16.31it/s, loss=0.00546]\n",
      "Epoch 3 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.43it/s, loss=0.112] \n",
      "Epoch 4 of train: :   1%|          | 2/280 [00:00<00:14, 18.64it/s, loss=0.00535]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0202\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.85it/s, loss=0.00386]\n",
      "Epoch 4 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.46it/s, loss=0.112] \n",
      "Epoch 5 of train: :   1%|          | 2/280 [00:00<00:14, 18.93it/s, loss=0.00312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0211\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.62it/s, loss=0.00302] \n",
      "Epoch 5 of val: : 100%|██████████| 120/120 [00:08<00:00, 14.92it/s, loss=0.111] \n",
      "Epoch 6 of train: :   1%|          | 2/280 [00:00<00:18, 14.66it/s, loss=0.00585]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0215\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.70it/s, loss=0.00252] \n",
      "Epoch 6 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.22it/s, loss=0.115] \n",
      "Epoch 7 of train: :   1%|          | 2/280 [00:00<00:16, 16.85it/s, loss=0.00344]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0209\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.72it/s, loss=0.00221] \n",
      "Epoch 7 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.00it/s, loss=0.11]   \n",
      "Epoch 8 of train: :   1%|          | 2/280 [00:00<00:13, 19.90it/s, loss=0.00266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0187\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 of train: : 100%|██████████| 280/280 [00:16<00:00, 17.34it/s, loss=0.002]   \n",
      "Epoch 8 of val: : 100%|██████████| 120/120 [00:07<00:00, 17.04it/s, loss=0.109] \n",
      "Epoch 9 of train: :   1%|          | 3/280 [00:00<00:14, 19.78it/s, loss=0.00204]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0182\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 of train: : 100%|██████████| 280/280 [00:16<00:00, 16.50it/s, loss=0.00183] \n",
      "Epoch 9 of val: : 100%|██████████| 120/120 [00:07<00:00, 16.90it/s, loss=0.109]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_set, test_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T10:15:14.123059Z",
     "start_time": "2020-04-01T10:15:14.076150Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'resid.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:31:00.112977Z",
     "start_time": "2020-04-03T07:30:52.596777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/218 [00:00<?, ?it/s]/home/rosneft_user_2500/anomaly-detection/src/models/torch/models.py:45: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "100%|██████████| 218/218 [00:05<00:00, 40.81it/s]\n",
      "100%|██████████| 94/94 [00:02<00:00, 44.07it/s]\n"
     ]
    }
   ],
   "source": [
    "resid_model = torch.load('resid.pth')\n",
    "resid_model.reset_states()\n",
    "\n",
    "train_resid_pred, test_resid_pred = forecast_tr_te(\n",
    "    resid_model, X_tr, X_te, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:31:00.492410Z",
     "start_time": "2020-04-03T07:31:00.184285Z"
    }
   },
   "outputs": [],
   "source": [
    "train_resid_pred = train_resid_pred.detach().numpy()\n",
    "test_resid_pred = test_resid_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T07:40:54.770923Z",
     "start_time": "2020-04-03T07:40:54.290140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef59d4ff856c4cb182fd3a67aac0a36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='component', max=40), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plotter_by_component([\n",
    "    compare_plot_from_2d_wrapper(np.r_[train_resid_pred, test_resid_pred], 'Next value prediction (LSTM)',\n",
    "                                 np.r_[smoothed_train, smoothed_test], 'Residuals (data - trend_pred)')\n",
    "], ['Residuals'], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
